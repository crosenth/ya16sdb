"""
Download and curate the NCBI 16S rRNA sequences
"""

import os
import sys

venv = os.environ.get('VIRTUAL_ENV')
if not venv:
    sys.exit('--> an active virtualenv is required'.format(venv))

# requirements installed in the virtualenv
from SCons.Script import (
    Variables, PathVariable, BoolVariable,
    ARGUMENTS, Help, Touch, Copy)

from bioscons.slurm import SlurmEnvironment

vrs = Variables(None, ARGUMENTS)
vrs.Add('email', 'email address for ncbi', 'crosenth@uw.edu')
vrs.Add('retry', 'ncbi retry milliseconds', '60000')
vrs.Add('nproc', ('Number of concurrent processes '), 25)
vrs.Add('nreq', ('Number of concurrent http requests to ncbi'), 3)
vrs.Add(BoolVariable('use_cluster', 'Use slurm', False))
vrs.Add('out', 'Path to output directory', 'output-ncbi')
vrs.Add(PathVariable('training_set',
                     'path to type strain training set',
                     'data/rdp_16s_type_strains.fasta.bz2'))
vrs.Add(PathVariable('blacklist',
                     'path to custom accession blacklist',
                     'data/blacklist.txt'))

# Provides access to options prior to instantiation of env object
# below; it's better to access variables through the env object.
varargs = dict({opt.key: opt.default for opt in vrs.options}, **vrs.args)
truevals = {True, 'yes', 'y', 'True', 'true', 't'}
nproc = varargs['nproc']
use_cluster = varargs['use_cluster'] in truevals

"""
Explicitly define PATH, giving preference to local executables; it's
best to use absolute paths for non-local executables rather than add
paths here to avoid accidental introduction of external
dependencies. Environment variables are inherited from the parent
shell from which scons is run and updated with the PATH defined
below, plus any additional environment variables in settings.conf
(all caps options only).
"""
environment_variables = dict(
    os.environ,
    PATH=':'.join([
        'bin',
        os.path.join(venv, 'bin'),
        '/usr/local/bin', '/usr/bin', '/bin']),
    OMP_NUM_THREADS=nproc,  # for FastTree
)

env = SlurmEnvironment(
    ENV=environment_variables,
    variables=vrs,
    use_cluster=use_cluster,
    shell='bash',
    time=False
)

env.Decider('MD5')

Help(vrs.GenerateHelpText(env))


def blast_db(env, sequence_file, output_base, dbtype='nucl'):
    prefix = dbtype[0]
    extensions = ['.{0}{1}'.format(prefix, suffix)
                  for suffix in ('hr', 'in', 'sq')]

    blast_out = env.Command(
        target=[output_base + ext for ext in extensions],
        source=sequence_file,
        action=('makeblastdb -dbtype {0} '
                '-in $SOURCE '
                '-out {1}'.format(dbtype, output_base)))

    env.Local(
        target=output_base,
        source=blast_out,
        action=('md5sum $SOURCES > $TARGET'))

    return blast_out

# start script

"""
get accessions (versions) of records with rrna 16s annotations from ncbi
"""
ncbi = env.Command(
    source=None,
    target='$out/esearch.txt',
    action=('deenurp -v ncbi_esearch '
            '--retry $retry '
            '--threads $nreq '
            '--log $out/ncbi.log '
            '--out $TARGET '
            '$email '
            '"16s[All Fields] AND '
            'rRNA[Feature Key] AND '
            'Bacteria[Organism] '
            'NOT(environmental samples[Organism] '
            'OR metagenomes[Organism] '
            'OR txid32644[Organism]) '
            'AND 500 : 999999999[Sequence Length]"'))
env.AlwaysBuild(ncbi)

"""
get accessions (versions) of records considered type strains

NCBI web blast uses `sequence_from_type[Filter]` so we will use that
NOTE: type_material[Filter] == sequence_from_type[Filter]
"""
types = env.Command(
    source=ncbi,
    target='$out/release/types/accessions.txt',
    action=('deenurp -v ncbi_esearch '
            '--retry $retry '
            '--threads $nreq '
            '--log $out/ncbi.log '
            '--out $TARGET '
            '$email '
            '"sequence_from_type[Filter] AND '
            '16s[All Fields] AND '
            'rRNA[Feature Key] AND '
            'Bacteria[Organism] '
            'NOT(environmental samples[Organism] '
            'OR metagenomes[Organism] '
            'OR txid32644[Organism]) '
            'AND 500 : 999999999[Sequence Length]"'))

"""
Touch these files in case they do not exist yet

current_accessions - text file list of the current accession
                     numbers downloaded and processed
no_features - text file list of accessions with no 16S features to be parsed
"""
current_accessions, no_features = env.Command(
    target=['$out/accessions.txt', '$out/cache/no_features.txt'],
    source=None,
    action=[Touch('${TARGETS[0]}'), Touch('${TARGETS[1]}')])
env.AlwaysBuild(current_accessions, no_features)
env.Precious(current_accessions, no_features)

"""
A grep diff between sequences we have, the blacklist and what
ncbi returns.  This will give us accession (versions) that are
not present to pass to entrez.py for download.
"""
new_accessions = env.Command(
    target=['$out/release/new_accessions.txt'],
    source=[current_accessions, no_features, ncbi],
    action=['cat ${SOURCES[:2]} $blacklist | '
            'grep '
            '--invert-match '
            '--fixed-strings '
            '--file /dev/stdin '
            '${SOURCES[2]} > $TARGET'])

"""
Download gb files and write fasta and seq_info right away
"""
raw_fasta, raw_info, raw_pubmed_ids, raw_references = env.Command(
    source=[no_features, types, new_accessions],
    target=['$out/cache/raw.fasta',
            '$out/cache/raw.csv',
            '$out/cache/raw_pubmed_ids.csv',
            '$out/cache/raw_references.csv'],
    action=('deenurp -v ncbi_extract_genbank '
            '--strand 1 '
            '--chunksize 1 '
            '--retry $retry '
            '--feature rrna::16s '
            '--log $out/ncbi.log '
            '--threads $nreq '
            '--no-features ${SOURCES[0]} '
            '--type-strains ${SOURCES[1]} '
            '--pubmed_ids ${TARGETS[2]} '
            '--references ${TARGETS[3]} '
            '$email ${SOURCES[2]} ${TARGETS[:2]}'))
env.Precious(raw_fasta, raw_info, raw_pubmed_ids, raw_references)

"""
Because records are appended and ncbi errors are common we need to
check sequences here for inconsistencies between
raw.fasta, raw.csv, raw_pubmed_ids and raw_references.csv
"""
sync_fasta, sync_info, sync_pubmed_ids, sync_references = env.Command(
    source=[raw_fasta,
            raw_info,
            raw_pubmed_ids,
            raw_references,
            no_features,
            current_accessions],
    target=['$out/cache/sync.fasta',
            '$out/cache/sync.csv',
            '$out/cache/sync_pubmed_ids.csv',
            '$out/cache/sync_references.csv'],
    action=['sync_records.py '
            '--accessions ${SOURCES[5]} '
            '${SOURCES[:5]} $TARGETS',
            # overwrite the "raw" files with the sync files
            Copy('${SOURCES[0]}', '${TARGETS[0]}'),
            Copy('${SOURCES[1]}', '${TARGETS[1]}'),
            Copy('${SOURCES[2]}', '${TARGETS[2]}'),
            Copy('${SOURCES[3]}', '${TARGETS[3]}')])

"""
Check sequence orientation and 16s region

TODO: save state of outputs to avoid extra work on records already processed
TODO: analyze no_16s matches, we want to make sure
      we're not losing valid sequences.
TODO: need pubs output here
"""
seqs, orientated_info, _, _, _ = env.Command(
    target=['$out/release/seqs.fasta',
            '$out/orientated/seq_info.csv',
            '$out/orientated/alignments.csv',
            '$out/orientated/notmatched.fasta',
            '$out/orientated/notmatched.csv'],
    source=[sync_fasta, '$training_set', sync_info],
    action=('deenurp orientate_sequences '
            '--threads $nproc '
            '--id 0.70 '
            '--log $out/orientated/vsearch.log '
            '--seq_info ${SOURCES[2]} '
            '--out ${TARGETS[0]} '
            '--out_seq_info ${TARGETS[1]} '
            '--out_csv ${TARGETS[2]} '
            '--out_notmatched ${TARGETS[3]} '
            '--out_notmatched_info ${TARGETS[4]} '
            '${SOURCES[:2]}'))

"""
Copy over files to release dir for processing
"""

"""
taxonomy md5 incase we need to update

TODO: move this process into its own pipeline
"""
tax_md5 = env.Command(
    target=['$out/taxonomy/taxdmp.zip.md5'],
    source=None,
    action=('wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdmp.zip.md5 '
            '--output-document $TARGET'))
env.AlwaysBuild(tax_md5)

"""
download and parse the full ncbi taxonomy
"""
tax_db, taxdmp = env.Command(
    target=['$out/taxonomy/ncbi_taxonomy.db', '$out/taxonomy/taxdmp.zip'],
    source=tax_md5,
    action=('taxit new_database '
            '--download-dir $out/taxonomy '
            '--database-file $TARGET'),
    use_cluster=False)

"""
update seq_info with latest tax_ids and add taxid_classified column
"""
seq_info, _ = env.Command(
    target=['$out/release/seq_info.csv', '$out/release/unknown_taxons.csv'],
    source=[orientated_info, tax_db],
    action=['taxit update_taxids '
            '--name-column organism '
            '--taxid-classified '
            '--append-lineage species '
            '--unknowns ${TARGETS[1]} '
            '--out ${TARGETS[0]} '
            '$SOURCES'])

"""
Make general taxtable
"""
tax = env.Command(
    target='$out/release/taxonomy.csv',
    source=[tax_db, seq_info],
    action=('taxit taxtable '
            '--full '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Count reference sequences that can be used for classification filtering
"""
tax_counts = env.Command(
    target='$out/release/tax_counts.csv',
    source=[tax, seq_info],
    action=('taxit count_taxids '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Drop sequences < 1200 bp and with more than 1% ambig and
partition into named and unnamed data sets.
"""
named_fasta, named_seqinfo, unnamed_fasta, unnamed_seqinfo = env.Command(
    target=['$out/release/named/seqs.fasta',
            '$out/release/named/seq_info.csv',
            '$out/release/unnamed/seqs.fasta',
            '$out/release/unnamed/seq_info.csv'],
    source=[seqs, seq_info],
    action=('deenurp partition_refs '
            # filtering
            '--min-length 1200 '
            '--prop-ambig-cutoff 0.01 '
            '--named-seqs ${TARGETS[0]} --named-info ${TARGETS[1]} '
            '--unnamed-seqs ${TARGETS[2]} --unnamed-info ${TARGETS[3]} '
            '$SOURCES')
)

"""
Make named taxtable
"""
named_tax = env.Command(
    target='$out/release/named/taxonomy.csv',
    source=[tax_db, named_seqinfo],
    action=('taxit taxtable '
            '--full '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Count reference sequences that can be used for classification filtering
"""
named_tax_counts = env.Command(
    target='$out/release/named/tax_counts.csv',
    source=[named_tax, named_seqinfo],
    action=('taxit count_taxids '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Make unnamed taxtable
"""
unnamed_tax = env.Command(
    target='$out/release/unnamed/taxonomy.csv',
    source=[tax_db, unnamed_seqinfo],
    action=('taxit taxtable '
            '--full '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Count reference sequences that can be used for classification filtering
"""
unnamed_tax_counts = env.Command(
    target='$out/release/unnamed/tax_counts.csv',
    source=[unnamed_tax, unnamed_seqinfo],
    action=('taxit count_taxids '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Create blast databases for all, named and unnamed
"""
all_blast = blast_db(env, seqs, '$out/release/blast')
named1200_blast = blast_db(env, named_fasta, '$out/release/named/blast')
unnamed1200_blast = blast_db(env, unnamed_fasta, '$out/release/unnamed/blast')

"""
Partition type strains
"""
types_fasta, types_seqinfo = env.Command(
    target=['$out/release/types/seqs.fasta',
            '$out/release/types/seq_info.csv'],
    source=[named_fasta, named_seqinfo],
    action=('deenurp partition_refs '
            '--type-seqs ${TARGETS[0]} '
            '--type-info ${TARGETS[1]} '
            '$SOURCES'))

"""
Make type strain taxtable
"""
types_tax = env.Command(
    target='$out/release/types/taxonomy.csv',
    source=[tax_db, types_seqinfo],
    action=('taxit taxtable '
            '--full '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Count reference sequences that can be used for classification filtering
"""
unnamed_ref_counts = env.Command(
    target='$out/release/types/tax_counts.csv',
    source=[types_tax, types_seqinfo],
    action=('taxit count_taxids '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Make type strain Blast database
"""
types_blast = blast_db(env, types_fasta, '$out/types/blast')

# Taxonomic filtering

"""
Deduplicate sequences by species rank

TODO: Either include that full taxonomy as an argument or engineer a
way to append the 'species' column to the seq_info.csv
"""
dedup_fasta, dedup_info = env.Command(
    target=['$out/release/filtered/dedup.fasta',
            '$out/release/filtered/dedup.csv'],
    source=[named_fasta, named_seqinfo],
    action=('deenurp deduplicate_sequences '
            '--group-by species '
            '--prefer-columns is_type '
            '$SOURCES $TARGETS'))

# Filter sequences. Use --threads if you need to to limit the number
# of processes - otherwise deenurp will use all of them!
filtered_fasta, filtered_seqinfo, filtered_details = env.Command(
    source=[seq_info, dedup_fasta, dedup_info, named_tax],
    target=['$out/release/filtered/seqs.fasta',
            '$out/release/filtered/seq_info.csv',
            '$out/release/filtered/details.csv'],
    action=['rm -f ${SOURCES[0]}.ssi && '
            'deenurp filter_outliers '
            '--filter-rank species '
            '--strategy cluster '
            '--distance-percentile 90 '
            '--min-distance 0.01 '
            '--max-distance 0.05 '
            '--min-seqs-for-filtering 5 '
            '--threads $nproc '
            '--filtered-seqinfo ${TARGETS[1]} '
            '--detailed-seqinfo ${TARGETS[2]} '
            '--previous-details $out/cache/details.csv '
            '${SOURCES[1:]} ${TARGETS[0]}',
            Copy('$out/cache/details.csv', '${TARGETS[2]}')],
    slurm_queue='full')

"""
Make filtered taxtable
"""
filtered_tax = env.Command(
    target='$out/release/filtered/taxonomy.csv',
    source=[tax_db, filtered_seqinfo],
    action=('taxit taxtable '
            '--full '
            '--seq-info ${SOURCES[1]} '
            '--out-file $TARGET '
            '${SOURCES[0]}'))

filtered_blast = blast_db(env, filtered_fasta, '$out/release/filtered/blast')

"""
Count reference sequences that can be used for classification filtering
"""
filtered_ref_counts = env.Command(
    target='$out/release/filtered/tax_counts.csv',
    source=[filtered_tax, filtered_seqinfo],
    action=('taxit count_taxids '
            '--seq-info ${SOURCES[1]} '
            '--out $TARGET '
            '${SOURCES[0]}'))

"""
Append contributers
"""
contributors = env.Command(
    source='.git/logs/HEAD',
    target='contributors.txt',
    action=('git log --all --format="%cN <%cE>" | sort | uniq > $TARGET'))
